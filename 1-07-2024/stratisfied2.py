# -*- coding: utf-8 -*-
"""stratisfied2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qizx6JQW5Vp8JX_eaZfxu01iwFP1As6f
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_absolute_error

# Load your data
df = pd.read_csv('/content/housing.csv')

# Discretize 'price' into categories for stratification
df['price_category'] = pd.qcut(df['price'], q=5, labels=False)

# Check the distribution of categories
print(df['price_category'].value_counts())

# Reduce the number of splits to avoid the ValueError
n_splits = 3  # Adjust as necessary
skf = StratifiedKFold(n_splits=n_splits)

# Split the dataset into feature and target as (x) and (y) axis
x = df[['size', 'bedrooms']].values
y = df['price_category'].values

# Initiate or define our model
model = LogisticRegression(max_iter=1000)

# Define our cross-validation method which is stratified K-fold
mae_scores = []

for train_index, test_index in skf.split(x, y):
    x_train, x_test = x[train_index], x[test_index]
    y_train, y_test = y[train_index], y[test_index]

    # Train the model with the set we get after looping
    model.fit(x_train, y_train)

    # Predict the test set
    y_pred = model.predict(x_test)
    mae = mean_absolute_error(y_test, y_pred)
    mae_scores.append(mae)

average_mae = np.mean(mae_scores)
print(f"Average Mean Absolute Error: {average_mae}")